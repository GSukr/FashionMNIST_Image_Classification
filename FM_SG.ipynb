{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMtUYlLMYLer"
   },
   "source": [
    "### Image classification using Fashion MNIST data set\n",
    "#### This notebook investigates whether multiple CNN models can achieve higher classification accuracy than any individual model. Two simple strategies for combining models are examined:\n",
    "\n",
    "> 1.   Classification based on the average class probabilities of models\n",
    "\n",
    "> 2.   Using the mode class for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iw0jg7HkU1Sy"
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import os # for file handling\n",
    "import pandas as pd # for data handling\n",
    "import numpy as np # for linear algebra\n",
    "import time # to time runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # to display images\n",
    "from sklearn import metrics # to evaluate classification accuracy\n",
    "import tensorflow as tf # for neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9XVY7_EHYcjT"
   },
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "dldlOy18YnkA",
    "outputId": "8e1ef58d-5316-48ce-c16b-ed813c735694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 6s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "x_train shape: (60000, 28, 28) , y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28) , y_test shape: (10000,)\n",
      "Number of classes:  10\n"
     ]
    }
   ],
   "source": [
    "# get fashion mnist data\n",
    "(x_train,y_train), (x_test,y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# show shapes of tensors\n",
    "print(\"x_train shape:\", x_train.shape, \", y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape, \", y_test shape:\", y_test.shape)\n",
    "\n",
    "# get number of classes\n",
    "nClasses = len(np.unique(y_train)) # number of output classes\n",
    "print(\"Number of classes: \", nClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0vCgZiggY8Wx"
   },
   "source": [
    "#### Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "UO4Cf8ZCVb18",
    "outputId": "07032fb1-5189-4202-ef01-7bc6e262900c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1) , y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28, 1) , y_test shape: (10000,)\n",
      "Image height = 28, image width = 28, number of channels = 1\n"
     ]
    }
   ],
   "source": [
    "# normalize grayscale pixel values (0-255) to (0,1)\n",
    "x_train = x_train.astype('float32')/255 # normalized training inputs\n",
    "x_test = x_test.astype('float32')/255 # normalized test inputs\n",
    "\n",
    "# reshape to needed input shape for network\n",
    "x_train, x_test = x_train.reshape((-1,28,28,1)), x_test.reshape((-1,28,28,1))\n",
    "input_shape = x_train.shape[1:] # input shape for network\n",
    "\n",
    "# show shapes of re-shaped tensors\n",
    "print(\"x_train shape:\", x_train.shape, \", y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape, \", y_test shape:\", y_test.shape)\n",
    "\n",
    "# get image dimensions\n",
    "img_h, img_w, img_channels = x_train.shape[1:] # size of image\n",
    "print(\"Image height = %d, image width = %d, number of channels = %d\" \n",
    "      %(img_h, img_w, img_channels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tnbugna9Z_7i"
   },
   "source": [
    "#### Define function to create Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0t1UyAfUGAQ"
   },
   "outputs": [],
   "source": [
    "def convNN(model, ch1, ch2, kernel, pool, nDense, drop, dropDense):\n",
    "    \n",
    "    model = tf.keras.models.Sequential() # create model                \n",
    "    \n",
    "    # first CONV => RELU => CONV => RELU => POOL layer set\n",
    "    model.add(Conv2D(ch1, kernel, padding=\"same\", \n",
    "                     activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(ch1, kernel, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool))\n",
    "    model.add(tf.keras.layers.Dropout(drop))\n",
    " \n",
    "    # second CONV => RELU => CONV => RELU => POOL layer set\n",
    "    model.add(Conv2D(ch2, kernel, padding=\"same\", \n",
    "                     activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(ch2, kernel, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool))\n",
    "    model.add(tf.keras.layers.Dropout(drop))\n",
    " \n",
    "    model.add(tf.keras.layers.Flatten()) \n",
    "    \n",
    "    # FC => RELU layers\n",
    "    model.add(tf.keras.layers.Dense(nDense, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropDense))\n",
    "    \n",
    "    # output softmax layer\n",
    "    model.add(tf.keras.layers.Dense(nClasses, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  optimizer=tf.keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XoV4YAnEaGi9"
   },
   "source": [
    "#### Specify parameters for convolution network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "colab_type": "code",
    "id": "gv72JOA4Obgr",
    "outputId": "0a2a57ae-83c7-475a-97d6-2b4d5909ebac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,679,082\n",
      "Trainable params: 1,677,674\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Parameters for CNN models (change as desired)\n",
    "ch1, ch2 = 32, 64 # number of output channels\n",
    "kernel = (3,3) # filter shape\n",
    "pool = (2,2) # max pool size\n",
    "nDense = 512 # dense layer size\n",
    "drop, dropDense = 0.25, 0.5\n",
    "\n",
    "# create model\n",
    "mod = convNN('model', ch1, ch2, kernel, pool, nDense, drop, dropDense)\n",
    "mod.summary() # show model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bIUuMmiVaa_2"
   },
   "source": [
    "#### Define function to plot accuracy with training and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42uggfi9V4Ii"
   },
   "outputs": [],
   "source": [
    "def plotHistorty(model, history):\n",
    "    # plot history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title(model+' accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZKw36AbLadKY"
   },
   "source": [
    "#### Specify parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2iGkIIwakBL"
   },
   "outputs": [],
   "source": [
    "batchSize = 32 # batch size for training\n",
    "epochs = 60 # number of training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgbQTfnYawhH"
   },
   "source": [
    "#### Train CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 13754
    },
    "colab_type": "code",
    "id": "e36k6SJlUErq",
    "outputId": "9b83340f-35f5-4fd4-b2ea-932084dd2990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: model_1\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/60\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.4970 - acc: 0.8320\n",
      "Epoch 00001: val_acc improved from -inf to 0.87740, saving model to model_1.weights.hdf5\n",
      "50000/50000 [==============================] - 290s 6ms/sample - loss: 0.4969 - acc: 0.8321 - val_loss: 0.3423 - val_acc: 0.8774\n",
      "Epoch 2/60\n",
      "14176/50000 [=======>......................] - ETA: 3:19 - loss: 0.3278 - acc: 0.8826"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-942381052784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                  \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                  callbacks=[checkpoint])\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mst\u001b[0m \u001b[0;31m# time to train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nModels = 3 # number of models to train\n",
    "probs = np.zeros((len(y_test), nClasses)) # mean probabilities for classes\n",
    "result = [] # for results\n",
    "\n",
    "# Train models\n",
    "for i in range(nModels):\n",
    "    model = 'model_'+str(i+1) # model name\n",
    "    print('\\nTraining Model: '+ model + '\\n')\n",
    "    bestWts = model+\".weights.hdf5\" # best weights file\n",
    "  \n",
    "  # checkpoint to save best model\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(bestWts,\n",
    "                                                  monitor='val_acc',\n",
    "                                                  verbose=1,\n",
    "                                                  save_best_only=True,\n",
    "                                                  mode='max')\n",
    "  \n",
    "  # create model\n",
    "    mod = convNN(model, ch1, ch2, kernel, pool, nDense, drop, dropDense)\n",
    "  \n",
    "    st = time.time() # start time for training\n",
    "  \n",
    "  # train models and maintain history\n",
    "    hist = mod.fit(x_train,\n",
    "                 tf.keras.utils.to_categorical(y_train, num_classes=nClasses), \n",
    "                 batch_size=batchSize,\n",
    "                 epochs=epochs, \n",
    "                 validation_split = 1/6,\n",
    "                 callbacks=[checkpoint])\n",
    "    t = time.time() - st # time to train model\n",
    "  \n",
    "    print(\"\\nTime to train classifier: %4.2f seconds\\n\" %(t))\n",
    "  \n",
    "    mod.save_weights(bestWts) # save best weights\n",
    "\n",
    "    prob = mod.predict(x_test) # predict probabilities for test examples\n",
    "    predicted = prob.argmax(axis=1) # most likely class\n",
    "    acc = metrics.accuracy_score(y_test, predicted) # best accuracy \n",
    "    print('%s Test accuracy = %4.2f%%\\n\\n' %(model, acc*100.0))\n",
    "  \n",
    "    probs += prob\n",
    "    predicted = probs.argmax(axis=1) # most likely class\n",
    "    accCum = metrics.accuracy_score(y_test, predicted) # best accuracy \n",
    "    print('%s Gestalt Test accuracy = %4.2f%%\\n\\n' %(model,accCum*100.0))\n",
    "  \n",
    "    result.append([model,acc,accCum,t])\n",
    "    plotHistorty(model, hist) # display training and test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lxKBGGNXmW_9"
   },
   "source": [
    "#### Show results on model accuracy, cumulative accuracy, and training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "4eCQcAA4rgyI",
    "outputId": "96d52e8c-d7d7-438d-e44f-79360ca53f28"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>cum. accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>0.9374</td>\n",
       "      <td>0.9374</td>\n",
       "      <td>954.793582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9411</td>\n",
       "      <td>962.929622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>0.9411</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>967.744258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  accuracy  cum. accuracy        time\n",
       "0  model_1    0.9374         0.9374  954.793582\n",
       "1  model_2    0.9356         0.9411  962.929622\n",
       "2  model_3    0.9411         0.9447  967.744258"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(result, \n",
    "                      columns=['model', 'accuracy', 'cum. accuracy', 'time'])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ezgrLIdYmuC-"
   },
   "source": [
    "#### specify label for classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6IC3VTMnTDr"
   },
   "outputs": [],
   "source": [
    "items = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', \n",
    "         'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] # labels\n",
    "item = dict(zip(range(10), items)) # create dictionary mapping class to labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gljkbcm3nBBc"
   },
   "source": [
    "#### Show confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "F97agyFxsgVi",
    "outputId": "9ad8781f-e919-4cab-a9b9-7f2ad5b50880"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>T-shirt/top</th>\n",
       "      <th>Trouser</th>\n",
       "      <th>Pullover</th>\n",
       "      <th>Dress</th>\n",
       "      <th>Coat</th>\n",
       "      <th>Sandal</th>\n",
       "      <th>Shirt</th>\n",
       "      <th>Sneaker</th>\n",
       "      <th>Bag</th>\n",
       "      <th>Ankle boot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T-shirt/top</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trouser</td>\n",
       "      <td>0</td>\n",
       "      <td>989</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pullover</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dress</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>950</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>935</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sandal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>989</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shirt</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>821</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sneaker</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>985</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bag</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ankle boot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          True  T-shirt/top  Trouser  Pullover  Dress  Coat  Sandal  Shirt  \\\n",
       "0  T-shirt/top          900        0        14      5     3       1     74   \n",
       "1      Trouser            0      989         0      8     0       0      1   \n",
       "2     Pullover           18        1       919      6    29       0     27   \n",
       "3        Dress            9        0         7    950    17       0     16   \n",
       "4         Coat            1        0        14     20   935       0     30   \n",
       "5       Sandal            0        0         0      0     0     989      0   \n",
       "6        Shirt           72        0        26     23    53       0    821   \n",
       "7      Sneaker            0        0         0      0     0       4      0   \n",
       "8          Bag            1        1         1      5     0       1      1   \n",
       "9   Ankle boot            0        0         0      0     0       3      0   \n",
       "\n",
       "   Sneaker  Bag  Ankle boot  \n",
       "0        0    3           0  \n",
       "1        0    2           0  \n",
       "2        0    0           0  \n",
       "3        0    1           0  \n",
       "4        0    0           0  \n",
       "5        9    0           2  \n",
       "6        0    5           0  \n",
       "7      985    0          11  \n",
       "8        1  989           0  \n",
       "9       26    1         970  "
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "cm = pd.DataFrame(cm, columns=items)\n",
    "cm.insert(0,\"True\",items)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9DNkiXv0nJsz"
   },
   "source": [
    "#### Show classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "e2HSBqb_p6FH",
    "outputId": "f761972d-8889-4c49-aabf-8b73d5ea2f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Ankle boot       0.99      0.97      0.98      1000\n",
      "         Bag       0.99      0.99      0.99      1000\n",
      "        Coat       0.90      0.94      0.92      1000\n",
      "       Dress       0.93      0.95      0.94      1000\n",
      "    Pullover       0.94      0.92      0.93      1000\n",
      "      Sandal       0.99      0.99      0.99      1000\n",
      "       Shirt       0.85      0.82      0.83      1000\n",
      "     Sneaker       0.96      0.98      0.97      1000\n",
      " T-shirt/top       0.90      0.90      0.90      1000\n",
      "     Trouser       1.00      0.99      0.99      1000\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report([items[i] for i in y_test], \n",
    "                                    [items[i] for i in predicted]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FHEZASPVnWEd"
   },
   "source": [
    "#### Use mode class for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "YoQi3UtQKa4G",
    "outputId": "1ac5b310-7b8b-4879-ba31-ee9ca791867a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing model_1\n",
      "processing model_2\n",
      "processing model_3\n",
      "Accuracy based on mode class = 94.37%\n"
     ]
    }
   ],
   "source": [
    "predClass = pd.DataFrame()\n",
    "for i in range(nModels):\n",
    "  model = 'model_'+str(i+1)\n",
    "  print(\"processing \" + model)\n",
    "  bestWts = model+\".weights.hdf5\" # best weights file\n",
    "  mod.load_weights(bestWts) # load best weights\n",
    "  prob = mod.predict(x_test) # predict probabilities for test examples\n",
    "  predClass[model] = prob.argmax(axis=1) # mst likely class\n",
    "  \n",
    "modeClass = predClass.mode(axis=1)\n",
    "modeAcc = metrics.accuracy_score(y_test, modeClass[0])\n",
    "print(\"Accuracy based on mode class = %4.2f%%\" %(100.0*modeAcc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZgxxR0dI6hEM"
   },
   "source": [
    "#### Compare accuracy for easy and hard classes\n",
    "- Note that 'T-shirt/top', 'Pullover', 'Coat', and  'Shirt' are harder to classify than other items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "HWjc3ZiV6ppb",
    "outputId": "48233ec0-6cf0-49fd-efb0-e799dc0d8c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data contains 4000 hard and 6000 easy examples\n",
      "Test accuracy with easy examples = 97.87%\n",
      "Test accuracy with hard examples = 89.38%\n"
     ]
    }
   ],
   "source": [
    "hardClasses = [0,2,4,6] # classes with low classification accuracy\n",
    "hardIndxTest = [i for i in range(len(y_test)) if y_test[i] in hardClasses]\n",
    "easyIndxTest = [i for i in range(len(y_test)) if y_test[i] not in hardClasses]\n",
    "print('Test data contains %d hard and %d easy examples' \n",
    "      %(len(hardIndxTest), len(easyIndxTest)))\n",
    "\n",
    "accEasy = metrics.accuracy_score(y_test[easyIndxTest], predicted[easyIndxTest])\n",
    "accHard = metrics.accuracy_score(y_test[hardIndxTest], predicted[hardIndxTest])\n",
    "\n",
    "print('Test accuracy with easy examples = %4.2f%%' %(100.0*accEasy)) \n",
    "print('Test accuracy with hard examples = %4.2f%%' %(100.0*accHard)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nyOUsvAGnjRv"
   },
   "source": [
    "#### Observations:\n",
    "\n",
    "1.   A simple CNN can achieve classification accuracy of over 93%\n",
    "2.   Combining 3 models improves accuracy around 94.4%\n",
    "\n",
    "1. It takes around 16 seconds per epoch using Colaboratory GPU accelerator and Test accuracy does not improve significantly after the first 20 epochs\n",
    "\n",
    "1.   Combining a few more models trained over 20 epochs may further improve classification accuracy in a resonable amount of time.\n",
    "\n",
    "1.   Classification accuracy is significantly lower for 4 classes: 'T-shirt/top', 'Pullover', 'Coat', and 'Shirt' \n",
    "\n",
    "\n",
    "\n",
    "#### Opportunities for improvement:\n",
    "\n",
    "\n",
    "1.   Devise alternate methods for combining models\n",
    "2.   Increase the diversity of constituent models\n",
    "\n",
    "1.   Introduce regularization methods that prevent over-fitting beyond 20 epochs\n",
    "2.   Develop a two-phased approach:  Predict using a combination of models in the first phase and use a separate model to re-classify examples predicted as 'T-shirt/top', 'Pullover', 'Coat', or 'Shirt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FM_SG.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
